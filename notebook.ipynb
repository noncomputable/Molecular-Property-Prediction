{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get molecular transformer embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get transformer embeddings\n",
    "train_emb = torch.load(\"data/train_sm.dat\")\n",
    "val_emb = torch.load(\"data/val_sm.dat\")\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "val_data = pd.read_csv('data/val.csv')\n",
    "\n",
    "mol_to_emb = {}\n",
    "\n",
    "sets = [(train_emb, train_data[\"Drug\"]), (val_emb, val_data[\"Drug\"])]\n",
    "for embs, datas in sets:\n",
    "    for emb, drug in zip(embs, datas):\n",
    "        mol_to_emb[drug] = emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import DataStructs\n",
    "from rdkit.Chem import rdMolDescriptors as rdmd\n",
    "\n",
    "\n",
    "def smiles_to_mols(smiles):\n",
    "    return [Chem.MolFromSmiles(smi) for smi in smiles]\n",
    "\n",
    "def get_representations(mols, smiles):\n",
    "    descriptors = []\n",
    "    for mol, smile in zip(mols, smiles):\n",
    "        molecular_weight = rdmd.CalcExactMolWt(mol)\n",
    "        logp = rdmd.CalcCrippenDescriptors(mol)[0]\n",
    "        arr = np.array([molecular_weight, logp])\n",
    "        fp = mol_to_emb[smile]\n",
    "        arr = np.concatenate((arr, fp))\n",
    "        descriptors.append(arr)\n",
    "    return np.stack(descriptors, axis=0)\n",
    "\n",
    "\n",
    "def get_reps_from_smiles(smiles):\n",
    "    mols = smiles_to_mols(smiles)\n",
    "    descriptors = get_representations(mols, smiles)\n",
    "    return descriptors\n",
    "\n",
    "\n",
    "X_train = get_reps_from_smiles(train_data.Drug)\n",
    "y_train = train_data.Y.values\n",
    "\n",
    "X_val = get_reps_from_smiles(val_data.Drug)\n",
    "y_val = val_data.Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def save_data(path, x, y):\n",
    "    x = get_reps_from_smiles(x)\n",
    "    y_unsq = torch.tensor(y, dtype = torch.float).unsqueeze(1)\n",
    "    together = torch.cat([torch.tensor(x, dtype = torch.float), y_unsq], dim = 1)\n",
    "    if not path.parent.is_dir():\n",
    "        os.mkdir(path.parent)\n",
    "    torch.save(together, path)\n",
    "\n",
    "dir_name = f\"trnsfm\"\n",
    "save_data(Path(f\"data/{dir_name}/val.dat\"), val_data.Drug, val_data.Y.values)\n",
    "save_data(Path(f\"data/{dir_name}/train.dat\"), train_data.Drug, train_data.Y.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import search\n",
    "search(num_samples = 10,\n",
    "       max_num_epochs = 100,\n",
    "       gpus_per_trial = 1,\n",
    "       name = \"mol_prop_pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"run_name\": \"linear\",\n",
    "  \"init_learning_rate\": .1,\n",
    "  \"lr_step_interval\": 35,\n",
    "  \"n_epochs\": 500,\n",
    "  \"epoch_log_interval\": 1,\n",
    "  \"batch_log_interval\": float('inf'),\n",
    "  \"val_interval\": 1,\n",
    "  \"save_interval\": 100,\n",
    "  \"batch_size\": 32,\n",
    "  \"fp_type\": \"trnsfm\",\n",
    "  \"dim_seq\": (256, 64),\n",
    "  \"dropout_pair\": (0, .5)\n",
    "}\n",
    "\n",
    "from experiment import experiment\n",
    "experiment(config, checkpoint_dir = \"checkpoints\", data_dir = \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.model import PermPredictor\n",
    "from core.dataset import MolData\n",
    "\n",
    "\n",
    "model = PermPredictor(514, (256, 64), (0, .5))\n",
    "checkpoint = torch.load(\"checkpoints/best.chkp\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "dataset = MolData(\"data/trnsfm/val.dat\")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle = False, batch_size = len(dataset))\n",
    "inputs, targets = next(iter(dataloader))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs).numpy()\n",
    "\n",
    "print(f\"Validation R2: {metrics.r2_score(targets, outputs)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chem]",
   "language": "python",
   "name": "conda-env-chem-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
